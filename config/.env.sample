# Enter your OpenAI key and details here.
# You need to add aditional details when using the UM Azure backend.
OPENAI_API_KEY=''
# OPENAI_API_BASE=''
OPENAI_API_VERSION='2024-02-01'
OPENAI_API_MODEL='gpt-4'
OPENAI_API_ORGANIZATION=''

# This replaces OPENAI_API_BASE, which breaks with LangChain's Azure API functions.
AZURE_OPENAI_ENDPOINT=''

# Specify log level for code. Defaults to DEBUG. Will default to INFO if invalid input is entered.
# Available options: DEBUG, INFO, WARN, ERROR, FATAL
LOG_LEVEL='INFO'

# Specify the path to the parent folder of video you want to use, located inside the 'Captions' folder. 
# The .srt files must be stored within this folder.
VIDEO_TO_USE = ''

# Specify the number of questions that will be attempted to be generated for the given video.
# There might not be enough clear context to generate the specified number of questions, 
# So the actual number of questions generated might be less, equal to number of relevant regions found useful to generate questions.
# Defaults to -1, which will generate one question per topic.
QUESTION_COUNT = -1

# Toggle for overwriting existing saved transcript if present, to reprocess and extract the transcript.
# 1 for overwriting existing models, 0 for not overwriting existing models.
# Defaults to 0.
OVERWRITE_EXISTING_TRANSCRIPT = 0

# Toggle for overwriting existing saved BERTopic models if present, to run a new model.
# NOTE: If you choose to overwrite the existing transcript data, this will be automatically set to 1 as well.
# 1 for overwriting existing models, 0 for not overwriting existing models.
# Defaults to 0.
OVERWRITE_EXISTING_TOPICMODEL = 0

# Toggle for overwriting existing saved question data if present, to generate new questions.
# NOTE: If you choose to overwrite the existing topic model, this will be automatically set to 1 as well.
# 1 for overwriting existing question data, 0 for not overwriting existing question data.
# Defaults to 0
OVERWRITE_EXISTING_QUESTIONS = 0

# Approximate window size of the captions taken from the .srt file.
# Value must be >= 1, but it is recommended to keep it between 10-30.
# Defaults to 30.
WINDOW_SIZE = 30

# If the duration of a given topic is longer than the context window, 
# The text only from the end of the topic's duration matching the length of the context window 
# Will be used for generating questions.
# If set to 0, all of the data will be used.
# Defaults to 600s for 10 minutes of context. Ideally should be a few minutes long at least for ebough relevent context.
RELEVANT_TEXT_CONTEXT_WINDOW = 600

# Specify the prompt for the LangChain model that runs atop the BERTopic model to generate a human-interpretable summary of the topics.
# Defaults to the prompt below. Do not adjust this unless you tuning the outputs for the generated topics.
LANGCHAIN_PROMPT = 'Give a single label that is only a few words long to summarize what these documents are about.'

# Specify the system prompt for question generation using the OpenAI API.
# Defaults to the prompt below. Do not adjust this unless you are tuning the outputs for the generated questions.
QUESTION__PROMPT = "You are a question-generating bot that generates questions for a given topic based on the provided relevant trancription text from a video."